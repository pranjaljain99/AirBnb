{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pylab\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "import pylab as plot\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the file\n",
    "listings = pd.read_csv('listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "plt.figure(figsize=(18,10))\n",
    "join_dates = pd.to_datetime(listings['host_since']).value_counts().resample('D').mean().fillna(0)\n",
    "join_dates.plot()\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('number of hosts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the price\n",
    "listings['price'] = (listings['price'].str.replace(r'[^-+\\d.]', '').astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only non zero values\n",
    "listings = listings[listings['accommodates'] != 0]\n",
    "listings = listings[listings['bedrooms'] != 0]\n",
    "listings = listings[listings['beds'] != 0]\n",
    "listings = listings[listings['price'] != 0.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed_df = listings[['price',\n",
    "           'room_type',\n",
    "           'accommodates',\n",
    "           'bathrooms',\n",
    "           'bedrooms',\n",
    "           'beds',\n",
    "           'review_scores_rating',\n",
    "           'instant_bookable',\n",
    "           'cancellation_policy',\n",
    "           'amenities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the string records into seperate elements and counting\n",
    "cancel_policy = pd.get_dummies(Transformed_df.cancellation_policy).astype(int)\n",
    "room_type = pd.get_dummies(Transformed_df.room_type).astype(int)\n",
    "instant_booking = pd.get_dummies(Transformed_df.instant_bookable, prefix = 'instant_booking').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing where instant booking is not availible\n",
    "instant_booking = instant_booking.drop('instant_booking_f', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop the original columns and replace them with new columns\n",
    "Transformed_df = Transformed_df.drop(['cancellation_policy', 'instant_bookable', 'room_type'], axis = 1)\n",
    "Transformed_df = pd.concat((Transformed_df, cancel_policy, instant_booking, room_type), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the amenities list to draw out how many amenities each listing has\n",
    "\n",
    "amenities_list = []\n",
    "\n",
    "for element in Transformed_df.amenities:\n",
    "    element = element[1:]\n",
    "    element = element[:-1]\n",
    "    x = element.split()\n",
    "    amenities_list.append(len(x))\n",
    "\n",
    "Transformed_df.amenities = amenities_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed_df= Transformed_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of prices\n",
    "mean = np.mean(Transformed_df.price)\n",
    "\n",
    "# standard deviation\n",
    "std = np.std(Transformed_df.price)\n",
    "\n",
    "print(\"mean : \" , mean)\n",
    "print (\"sd   : \" ,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training and test sets with a 60% and 40% size of original\n",
    "split_data = Transformed_df.drop(['price'], axis = 1)\n",
    "split_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = split_data\n",
    "y = Transformed_df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "print(format(logistic.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_reg = linear_model.LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "linear_reg_error = metrics.median_absolute_error(y_test, linear_reg.predict(X_test))\n",
    "print (\"Error in Linear Regression: \" + str(linear_reg_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge = linear_model.Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_error = metrics.median_absolute_error(y_test, ridge.predict(X_test))\n",
    "print (\"Error in Ridge: \" + str(ridge_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector Machine\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_error = metrics.median_absolute_error(y_test, svm.predict(X_test))\n",
    "\n",
    "#print('Accuracy of SVM classifier: {:.2f}'.format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier: {:.2f}'.format(decision.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)\n",
    "print('Accuracy of RF classifier: {:.2f}'.format(classifier.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=decision.predict(X_test) # This is changed every time for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error: %.2f\" % np.mean((decision.predict(X_test) - y_test) ** 2))# This is changed every time for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "print(pd.crosstab(y_test,y_pred,colnames=[\"predicted\"],rownames=[\"Actual\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
